{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "import h5py\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=3000)])\n",
    "  except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = h5py.File('datasets/train_happy.h5', \"r\")\n",
    "train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "test_dataset = h5py.File('datasets/test_happy.h5', \"r\")\n",
    "test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 600\n",
      "number of test examples = 150\n",
      "X_train shape: (600, 64, 64, 3)\n",
      "Y_train shape: (600, 1)\n",
      "X_test shape: (150, 64, 64, 3)\n",
      "Y_test shape: (150, 1)\n"
     ]
    }
   ],
   "source": [
    "# Normalize image vectors\n",
    "X_train = X_train_orig/255.\n",
    "X_test = X_test_orig/255.\n",
    "\n",
    "# Reshape\n",
    "Y_train = Y_train_orig.T\n",
    "Y_test = Y_test_orig.T\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HappyModel(input_shape):\n",
    "    \n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # CONV -> BN -> RELU Block applied to X\n",
    "    X = Conv2D(32, (7, 7), strides = (1, 1), name = 'conv0')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn0')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # MAXPOOL\n",
    "    X = MaxPooling2D((2, 2), name='max_pool')(X)\n",
    "\n",
    "    # FLATTEN X\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(1, activation='sigmoid', name='fc')(X)\n",
    "\n",
    "    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.\n",
    "    model = Model(inputs = X_input, outputs = X, name='HappyModel')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "happyModel = HappyModel(X_train.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=0.01)\n",
    "happyModel.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 2.1648 - val_loss: 1.1297\n",
      "Epoch 2/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.3800 - val_loss: 0.6198\n",
      "Epoch 3/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.1977 - val_loss: 0.6396\n",
      "Epoch 4/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.2255 - val_loss: 0.5261\n",
      "Epoch 5/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.1821 - val_loss: 0.4012\n",
      "Epoch 6/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.1139 - val_loss: 0.3779\n",
      "Epoch 7/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.1031 - val_loss: 0.3542\n",
      "Epoch 8/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.1027 - val_loss: 0.2944\n",
      "Epoch 9/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0587 - val_loss: 0.2532\n",
      "Epoch 10/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0690 - val_loss: 0.2290\n",
      "Epoch 11/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0822 - val_loss: 0.2135\n",
      "Epoch 12/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0601 - val_loss: 0.2065\n",
      "Epoch 13/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0414 - val_loss: 0.1898\n",
      "Epoch 14/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0370 - val_loss: 0.2801\n",
      "Epoch 15/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0392 - val_loss: 0.1774\n",
      "Epoch 16/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0357 - val_loss: 0.1514\n",
      "Epoch 17/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0266 - val_loss: 0.1635\n",
      "Epoch 18/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0271 - val_loss: 0.1385\n",
      "Epoch 19/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0462 - val_loss: 0.1544\n",
      "Epoch 20/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0557 - val_loss: 0.1453\n",
      "Epoch 21/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0396 - val_loss: 0.3487\n",
      "Epoch 22/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0280 - val_loss: 0.3035\n",
      "Epoch 23/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0428 - val_loss: 2.1563\n",
      "Epoch 24/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0306 - val_loss: 0.1622\n",
      "Epoch 25/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0243 - val_loss: 1.0882\n",
      "Epoch 26/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.3327\n",
      "Epoch 27/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.6456\n",
      "Epoch 28/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.0804\n",
      "Epoch 29/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0386 - val_loss: 0.3584\n",
      "Epoch 30/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.1169\n",
      "Epoch 31/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0304 - val_loss: 0.3497\n",
      "Epoch 32/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.0224 - val_loss: 0.1407\n",
      "Epoch 33/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.0204 - val_loss: 0.1913\n",
      "Epoch 34/200\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.0181 - val_loss: 0.3260\n",
      "Epoch 35/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.0358 - val_loss: 0.0746\n",
      "Epoch 36/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.0222 - val_loss: 0.1223\n",
      "Epoch 37/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.0644 - val_loss: 0.0974\n",
      "Epoch 38/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.0327 - val_loss: 0.4291\n",
      "Epoch 39/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0447 - val_loss: 1.4699\n",
      "Epoch 40/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.0866 - val_loss: 0.2017\n",
      "Epoch 41/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.0593 - val_loss: 0.9837\n",
      "Epoch 42/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.1469 - val_loss: 0.1818\n",
      "Epoch 43/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.0947 - val_loss: 2.1194\n",
      "Epoch 44/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.0251 - val_loss: 0.5517\n",
      "Epoch 45/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.4308\n",
      "Epoch 46/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.1313 - val_loss: 0.4009\n",
      "Epoch 47/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0504 - val_loss: 6.2796\n",
      "Epoch 48/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 3.2652\n",
      "Epoch 49/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 2.4275\n",
      "Epoch 50/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0593 - val_loss: 1.9921\n",
      "Epoch 51/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 1.5921\n",
      "Epoch 52/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0687\n",
      "Epoch 53/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0330 - val_loss: 0.0545\n",
      "Epoch 54/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.0223 - val_loss: 0.3257\n",
      "Epoch 55/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0883\n",
      "Epoch 56/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.2305\n",
      "Epoch 57/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0841\n",
      "Epoch 58/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.2372\n",
      "Epoch 59/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0069 - val_loss: 0.1019\n",
      "Epoch 60/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0681\n",
      "Epoch 61/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0242 - val_loss: 0.0660\n",
      "Epoch 62/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0358 - val_loss: 0.1126\n",
      "Epoch 63/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.1237\n",
      "Epoch 64/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0585\n",
      "Epoch 65/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0237 - val_loss: 0.0731\n",
      "Epoch 66/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0552\n",
      "Epoch 67/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.1058\n",
      "Epoch 68/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0448\n",
      "Epoch 69/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0845\n",
      "Epoch 70/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0475\n",
      "Epoch 71/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.1417\n",
      "Epoch 72/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0587\n",
      "Epoch 73/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0163 - val_loss: 0.0787\n",
      "Epoch 74/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0057 - val_loss: 0.0849\n",
      "Epoch 75/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0026 - val_loss: 0.0547\n",
      "Epoch 76/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0014 - val_loss: 0.0479\n",
      "Epoch 77/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0864\n",
      "Epoch 78/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.0047 - val_loss: 0.0934\n",
      "Epoch 79/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.1117\n",
      "Epoch 80/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0160 - val_loss: 0.0416\n",
      "Epoch 81/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.1518\n",
      "Epoch 82/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.2361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.2385\n",
      "Epoch 84/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0574\n",
      "Epoch 85/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0031 - val_loss: 0.0431\n",
      "Epoch 86/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0590\n",
      "Epoch 87/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.1109\n",
      "Epoch 88/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.3690\n",
      "Epoch 89/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0929\n",
      "Epoch 90/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.2249\n",
      "Epoch 91/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0502\n",
      "Epoch 92/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0819\n",
      "Epoch 93/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.1054\n",
      "Epoch 94/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0486\n",
      "Epoch 95/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0061 - val_loss: 0.0743\n",
      "Epoch 96/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0263 - val_loss: 0.5614\n",
      "Epoch 97/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.2897\n",
      "Epoch 98/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.1117\n",
      "Epoch 99/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.4251\n",
      "Epoch 100/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0432 - val_loss: 0.0889\n",
      "Epoch 101/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.4494\n",
      "Epoch 102/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0029 - val_loss: 0.8186\n",
      "Epoch 103/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.4442\n",
      "Epoch 104/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.2081\n",
      "Epoch 105/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.2525\n",
      "Epoch 106/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0030 - val_loss: 0.1284\n",
      "Epoch 107/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0049 - val_loss: 0.1625\n",
      "Epoch 108/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0918\n",
      "Epoch 109/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0500\n",
      "Epoch 110/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 7.0753e-04 - val_loss: 0.0853\n",
      "Epoch 111/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 8.0071e-04 - val_loss: 0.0817\n",
      "Epoch 112/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 6.9393e-04 - val_loss: 0.0486\n",
      "Epoch 113/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 0.0678\n",
      "Epoch 114/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.1898\n",
      "Epoch 115/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0374\n",
      "Epoch 116/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 8.4248e-04 - val_loss: 0.0425\n",
      "Epoch 117/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0500\n",
      "Epoch 118/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0471\n",
      "Epoch 119/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 8.6140e-04 - val_loss: 0.0674\n",
      "Epoch 120/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 2.4708e-04 - val_loss: 0.0436\n",
      "Epoch 121/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 2.8167e-04 - val_loss: 0.0457\n",
      "Epoch 122/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 2.1254e-04 - val_loss: 0.0570\n",
      "Epoch 123/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 1.6918e-04 - val_loss: 0.0499\n",
      "Epoch 124/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1.7586e-04 - val_loss: 0.0543\n",
      "Epoch 125/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1.4510e-04 - val_loss: 0.0508\n",
      "Epoch 126/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1.0798e-04 - val_loss: 0.0523\n",
      "Epoch 127/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 9.9276e-05 - val_loss: 0.0504\n",
      "Epoch 128/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1.0306e-04 - val_loss: 0.0517\n",
      "Epoch 129/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1.0751e-04 - val_loss: 0.0519\n",
      "Epoch 130/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 1.0014e-04 - val_loss: 0.0532\n",
      "Epoch 131/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 9.8004e-05 - val_loss: 0.0510\n",
      "Epoch 132/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 8.6339e-05 - val_loss: 0.0511\n",
      "Epoch 133/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 8.7904e-05 - val_loss: 0.0512\n",
      "Epoch 134/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 9.8298e-05 - val_loss: 0.0508\n",
      "Epoch 135/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 9.7289e-05 - val_loss: 0.0511\n",
      "Epoch 136/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 8.8598e-05 - val_loss: 0.0507\n",
      "Epoch 137/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 7.9496e-05 - val_loss: 0.0509\n",
      "Epoch 138/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 8.0380e-05 - val_loss: 0.0519\n",
      "Epoch 139/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 8.2660e-05 - val_loss: 0.0520\n",
      "Epoch 140/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 7.8456e-05 - val_loss: 0.0499\n",
      "Epoch 141/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 7.0156e-05 - val_loss: 0.0503\n",
      "Epoch 142/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 7.2195e-05 - val_loss: 0.0506\n",
      "Epoch 143/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 7.6411e-05 - val_loss: 0.0506\n",
      "Epoch 144/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 7.7605e-05 - val_loss: 0.0506\n",
      "Epoch 145/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 6.8772e-05 - val_loss: 0.0497\n",
      "Epoch 146/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 8.7790e-05 - val_loss: 0.0488\n",
      "Epoch 147/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 6.9343e-05 - val_loss: 0.0509\n",
      "Epoch 148/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 6.8854e-05 - val_loss: 0.0514\n",
      "Epoch 149/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 6.9017e-05 - val_loss: 0.0512\n",
      "Epoch 150/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 7.2059e-05 - val_loss: 0.0500\n",
      "Epoch 151/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 6.6646e-05 - val_loss: 0.0510\n",
      "Epoch 152/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 7.7810e-05 - val_loss: 0.0496\n",
      "Epoch 153/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 7.3160e-05 - val_loss: 0.0487\n",
      "Epoch 154/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 6.3815e-05 - val_loss: 0.0513\n",
      "Epoch 155/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 6.7629e-05 - val_loss: 0.0490\n",
      "Epoch 156/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 5.9436e-05 - val_loss: 0.0529\n",
      "Epoch 157/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 6.7092e-05 - val_loss: 0.0521\n",
      "Epoch 158/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 6.1186e-05 - val_loss: 0.0509\n",
      "Epoch 159/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 6.8505e-05 - val_loss: 0.0498\n",
      "Epoch 160/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 5.3369e-05 - val_loss: 0.0515\n",
      "Epoch 161/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 5.3402e-05 - val_loss: 0.0513\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 9ms/step - loss: 5.4527e-05 - val_loss: 0.0506\n",
      "Epoch 163/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 5.8501e-05 - val_loss: 0.0520\n",
      "Epoch 164/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 5.2165e-05 - val_loss: 0.0497\n",
      "Epoch 165/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 5.7590e-05 - val_loss: 0.0508\n",
      "Epoch 166/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 6.1630e-05 - val_loss: 0.0487\n",
      "Epoch 167/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 5.8324e-05 - val_loss: 0.0525\n",
      "Epoch 168/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 5.8547e-05 - val_loss: 0.0507\n",
      "Epoch 169/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 6.3515e-05 - val_loss: 0.0498\n",
      "Epoch 170/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 5.4254e-05 - val_loss: 0.0523\n",
      "Epoch 171/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 6.3131e-05 - val_loss: 0.0510\n",
      "Epoch 172/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 5.1036e-05 - val_loss: 0.0495\n",
      "Epoch 173/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 4.9014e-05 - val_loss: 0.0513\n",
      "Epoch 174/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 5.1538e-05 - val_loss: 0.0497\n",
      "Epoch 175/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 5.2449e-05 - val_loss: 0.0489\n",
      "Epoch 176/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 4.7919e-05 - val_loss: 0.0513\n",
      "Epoch 177/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 4.7832e-05 - val_loss: 0.0509\n",
      "Epoch 178/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 5.3305e-05 - val_loss: 0.0524\n",
      "Epoch 179/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 5.3977e-05 - val_loss: 0.0503\n",
      "Epoch 180/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 4.7452e-05 - val_loss: 0.0507\n",
      "Epoch 181/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 4.8121e-05 - val_loss: 0.0491\n",
      "Epoch 182/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 5.0672e-05 - val_loss: 0.0550\n",
      "Epoch 183/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 4.1873e-05 - val_loss: 0.0508\n",
      "Epoch 184/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 5.0613e-05 - val_loss: 0.0487\n",
      "Epoch 185/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 6.0860e-05 - val_loss: 0.0554\n",
      "Epoch 186/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 4.9689e-05 - val_loss: 0.0512\n",
      "Epoch 187/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 4.4541e-05 - val_loss: 0.0505\n",
      "Epoch 188/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 4.3715e-05 - val_loss: 0.0490\n",
      "Epoch 189/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 4.3209e-05 - val_loss: 0.0502\n",
      "Epoch 190/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 4.0756e-05 - val_loss: 0.0501\n",
      "Epoch 191/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 4.7997e-05 - val_loss: 0.0510\n",
      "Epoch 192/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 4.5071e-05 - val_loss: 0.0514\n",
      "Epoch 193/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 4.0300e-05 - val_loss: 0.0499\n",
      "Epoch 194/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 4.1965e-05 - val_loss: 0.0492\n",
      "Epoch 195/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 4.3521e-05 - val_loss: 0.0484\n",
      "Epoch 196/200\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 4.2454e-05 - val_loss: 0.0509\n",
      "Epoch 197/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 4.3324e-05 - val_loss: 0.0537\n",
      "Epoch 198/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 4.4449e-05 - val_loss: 0.0500\n",
      "Epoch 199/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 4.2091e-05 - val_loss: 0.0509\n",
      "Epoch 200/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 4.1754e-05 - val_loss: 0.0508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f86d8f67210>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happyModel.fit(X_train,Y_train,epochs=200,validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f86cc6f98d0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = pd.DataFrame(happyModel.history.history)\n",
    "losses[['loss','val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        66\n",
      "           1       0.98      1.00      0.99        84\n",
      "\n",
      "    accuracy                           0.99       150\n",
      "   macro avg       0.99      0.98      0.99       150\n",
      "weighted avg       0.99      0.99      0.99       150\n",
      "\n",
      "[[64  2]\n",
      " [ 0 84]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "predictions = happyModel.predict(X_test)\n",
    "predictions = [1 if i>0.5 else 0 for i in predictions[:,0]]\n",
    "print(classification_report(Y_test,predictions))\n",
    "print(confusion_matrix(Y_test,predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
